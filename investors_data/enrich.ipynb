{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80bbfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "us_entries = json.loads(open('/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k.json').read())\n",
    "\n",
    "print(len(us_entries))\n",
    "\n",
    "us_entries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa8d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, HttpUrl, Field\n",
    "\n",
    "class InvestorQuickProfile(BaseModel):\n",
    "    investor_name: str\n",
    "    firm_name: Optional[str] = None\n",
    "\n",
    "    personal_bio: Optional[str] = Field(description=\"2–4 sentences, summarized\") \n",
    "    interests: Optional[List[str]] = Field(description=\"3–8 concise topics the investor is passionate about\")\n",
    "    career_background: Optional[str] = Field(description=\"one short paragraph\")\n",
    "    previous_investments: Optional[List[str]] = Field(description=\"up to 15 company names\")\n",
    "    hometown: Optional[str] = Field(description=\"only if explicitly stated\")\n",
    "\n",
    "    personal_twitter_profile: Optional[str] = Field(description=\"full profile URL\")\n",
    "    personal_linkedin_url: Optional[str] = Field(description=\"full profile URL\")\n",
    "    firm_twitter_profile: Optional[str] = Field(description=\"full profile URL\")\n",
    "    firm_linkedin_url: Optional[str] = Field(description=\"full profile URL\")\n",
    "\n",
    "    investment_focus: Optional[str] = Field(description=\"e.g., sectors/stages/types of startups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98895d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "prompt = \"\"\"\n",
    "You are a web research agent that find information on investors.\n",
    "\n",
    "You will get an investor's name and their firm name if its available.\n",
    "\n",
    "Task:\n",
    "Return a concise investor profile as JSON that matches the schema exactly.\n",
    "\n",
    "Rules:\n",
    "- Output JSON only (no prose).\n",
    "- Be brief and factual; avoid hype.\n",
    "- If a field can’t be verified from credible sources, set it to null (don’t guess).\n",
    "- Disambiguate names using firm pages, LinkedIn, and geography.\n",
    "- Do NOT infer “hometown” from “based in”; only fill if explicitly stated as hometown/grew up in.\n",
    "- Limit `interests` to 3–8 items and `previous_investments` to at most 15 notable companies.\n",
    "- Normalize URLs to https when possible.\n",
    "\n",
    "Don't cite any sources. Provide the \n",
    "\n",
    "Here's the given investor details:\n",
    "{investor}\n",
    "\"\"\"\n",
    "\n",
    "def get_investor_profile(entry):\n",
    "    \n",
    "    investor = str(entry.get(\"name\", \"\")) + \" from the following firm: \" + str(entry.get(\"firm\", \"\"))\n",
    "\n",
    "    response = client.responses.parse(\n",
    "        model=\"gpt-5-mini\",\n",
    "        tools=[{\"type\": \"web_search_preview\"}],\n",
    "        input=prompt.format(investor=investor),\n",
    "        text_format=InvestorQuickProfile\n",
    "    )\n",
    "\n",
    "    return response.output_parsed\n",
    "\n",
    "# get_investor_profile(us_entries[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6fae84",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3679bc98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668d15da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_PATH = \"/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k.json\"\n",
    "BATCH_SIZE = 800\n",
    "MAX_WORKERS = 800  # tune based on rate limits\n",
    "\n",
    "\n",
    "def to_plain_dict(model_obj):\n",
    "    \"\"\"Return a plain dict from a pydantic model-like object, or None.\"\"\"\n",
    "    if model_obj is None:\n",
    "        return None\n",
    "    if hasattr(model_obj, \"model_dump\"):\n",
    "        return model_obj.model_dump()\n",
    "    if hasattr(model_obj, \"dict\"):\n",
    "        return model_obj.dict()\n",
    "    return model_obj\n",
    "\n",
    "\n",
    "def enrich_single_entry(entry):\n",
    "    \"\"\"Fetch structured profile and return as dict; never raise.\"\"\"\n",
    "    try:\n",
    "        profile = get_investor_profile(entry)\n",
    "        return to_plain_dict(profile)\n",
    "    except Exception as error:\n",
    "        print(f\"[enrich_single_entry] error for '{entry.get('name')}' ({entry.get('firm')}): {error}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Determine remaining items to process (skip already enriched)\n",
    "TOTAL = len(us_entries)\n",
    "indices_to_process = [i for i in range(TOTAL) if us_entries[i].get(\"enrichment\") is None]\n",
    "\n",
    "if not indices_to_process:\n",
    "    print(\"Nothing to process. All entries are already enriched.\")\n",
    "else:\n",
    "    total_progress = tqdm(total=len(indices_to_process), desc=\"Total items\", unit=\"inv\", leave=True)\n",
    "\n",
    "    for batch_start in range(0, len(indices_to_process), BATCH_SIZE):\n",
    "        batch_indices = indices_to_process[batch_start: batch_start + BATCH_SIZE]\n",
    "        batch_desc = f\"Batch {batch_start // BATCH_SIZE + 1}\"\n",
    "        batch_progress = tqdm(total=len(batch_indices), desc=batch_desc, unit=\"inv\", leave=False)\n",
    "\n",
    "        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "            future_by_index = {executor.submit(enrich_single_entry, us_entries[i]): i for i in batch_indices}\n",
    "            for future in as_completed(future_by_index):\n",
    "                idx = future_by_index[future]\n",
    "                try:\n",
    "                    enrichment_value = future.result()\n",
    "                except Exception as error:\n",
    "                    print(f\"[batch] future failed at index {idx}: {error}\")\n",
    "                    enrichment_value = None\n",
    "                us_entries[idx][\"enrichment\"] = enrichment_value\n",
    "                batch_progress.update(1)\n",
    "                total_progress.update(1)\n",
    "\n",
    "        batch_progress.close()\n",
    "\n",
    "        # Persist after each batch\n",
    "        with open(DATA_PATH, \"w\") as outfile:\n",
    "            json.dump(us_entries, outfile, ensure_ascii=False)\n",
    "\n",
    "    total_progress.close()\n",
    "\n",
    "# Final summary\n",
    "to_process_count = len(indices_to_process)\n",
    "enriched_count = sum(1 for i in indices_to_process if us_entries[i].get(\"enrichment\") is not None)\n",
    "print(f\"Finished. Enriched {enriched_count}/{to_process_count} entries into {DATA_PATH}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbca469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01aee5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 6597 enriched entries to /Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_enriched_only.json.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "OUTPUT_PATH = \"/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_enriched_only.json\"\n",
    "\n",
    "# Load entries from memory if present, otherwise from disk\n",
    "try:\n",
    "    entries_source = us_entries\n",
    "except NameError:\n",
    "    source_path = DATA_PATH if 'DATA_PATH' in globals() else \\\n",
    "        \"/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k.json\"\n",
    "    with open(source_path, \"r\") as infile:\n",
    "        entries_source = json.load(infile)\n",
    "\n",
    "\n",
    "def has_nonempty_enrichment(entry):\n",
    "    \"\"\"Return True if the entry has a non-empty enrichment value.\"\"\"\n",
    "    enrichment = entry.get(\"enrichment\")\n",
    "    if enrichment is None:\n",
    "        return False\n",
    "    if enrichment == {}:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "filtered_entries = [entry for entry in entries_source if has_nonempty_enrichment(entry)]\n",
    "\n",
    "with open(OUTPUT_PATH, \"w\") as outfile:\n",
    "    json.dump(filtered_entries, outfile, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(filtered_entries)} enriched entries to {OUTPUT_PATH}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c08886d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total enriched entries: 6597\n",
      "\n",
      "Twitter Profile Stats:\n",
      "personal_twitter_profile present: 885\n",
      "Valid links: 874\n",
      "Invalid links: 11\n",
      "Missing/null personal_twitter_profile: 5712\n",
      "\n",
      "LinkedIn Profile Stats:\n",
      "personal_linkedin_url present: 1762\n",
      "Valid links: 1734\n",
      "Invalid links: 28\n",
      "Missing/null personal_linkedin_url: 4835\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "ENRICHED_ONLY_PATH = \"/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_enriched_only.json\"\n",
    "\n",
    "with open(ENRICHED_ONLY_PATH, \"r\") as infile:\n",
    "    enriched_only = json.load(infile)\n",
    "\n",
    "\n",
    "def is_valid_twitter_url(url: str) -> bool:\n",
    "    \"\"\"Basic validation for Twitter/X profile URLs.\"\"\"\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return False\n",
    "    parsed = urlparse(url.strip())\n",
    "    if parsed.scheme not in (\"http\", \"https\"):\n",
    "        return False\n",
    "    if not parsed.netloc:\n",
    "        return False\n",
    "    host = parsed.netloc.lower()\n",
    "    if not (host.endswith(\"twitter.com\") or host.endswith(\"x.com\")):\n",
    "        return False\n",
    "    path = parsed.path.strip(\"/\")\n",
    "    if not path:\n",
    "        return False\n",
    "    segments = [seg for seg in path.split(\"/\") if seg]\n",
    "    if len(segments) != 1:\n",
    "        return False\n",
    "    username = segments[0]\n",
    "    if not re.fullmatch(r\"[A-Za-z0-9_]{1,15}\", username):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def is_valid_linkedin_url(url: str) -> bool:\n",
    "    \"\"\"Basic validation for LinkedIn profile URLs.\"\"\"\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return False\n",
    "    parsed = urlparse(url.strip())\n",
    "    if parsed.scheme not in (\"http\", \"https\"):\n",
    "        return False\n",
    "    if not parsed.netloc:\n",
    "        return False\n",
    "    host = parsed.netloc.lower()\n",
    "    if not host.endswith(\"linkedin.com\"):\n",
    "        return False\n",
    "    path = parsed.path.strip(\"/\")\n",
    "    if not path:\n",
    "        return False\n",
    "    segments = [seg for seg in path.split(\"/\") if seg]\n",
    "    if len(segments) < 2 or segments[0] != \"in\":\n",
    "        return False\n",
    "    username = segments[1]\n",
    "    if not re.fullmatch(r\"[A-Za-z0-9\\-]{1,100}\", username):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "total = len(enriched_only)\n",
    "\n",
    "# Twitter stats\n",
    "twitter_with_value = 0\n",
    "twitter_invalid = 0\n",
    "twitter_valid = 0\n",
    "twitter_missing = 0\n",
    "\n",
    "# LinkedIn stats\n",
    "linkedin_with_value = 0\n",
    "linkedin_invalid = 0\n",
    "linkedin_valid = 0\n",
    "linkedin_missing = 0\n",
    "\n",
    "for entry in enriched_only:\n",
    "    enrichment = entry.get(\"enrichment\") or {}\n",
    "    \n",
    "    # Check Twitter\n",
    "    twitter_url = enrichment.get(\"personal_twitter_profile\")\n",
    "    if twitter_url is None or (isinstance(twitter_url, str) and twitter_url.strip() == \"\"):\n",
    "        twitter_missing += 1\n",
    "    else:\n",
    "        twitter_with_value += 1\n",
    "        if is_valid_twitter_url(twitter_url):\n",
    "            twitter_valid += 1\n",
    "        else:\n",
    "            twitter_invalid += 1\n",
    "    \n",
    "    # Check LinkedIn\n",
    "    linkedin_url = enrichment.get(\"personal_linkedin_url\")\n",
    "    if linkedin_url is None or (isinstance(linkedin_url, str) and linkedin_url.strip() == \"\"):\n",
    "        linkedin_missing += 1\n",
    "    else:\n",
    "        linkedin_with_value += 1\n",
    "        if is_valid_linkedin_url(linkedin_url):\n",
    "            linkedin_valid += 1\n",
    "        else:\n",
    "            linkedin_invalid += 1\n",
    "\n",
    "print(f\"Total enriched entries: {total}\")\n",
    "print()\n",
    "print(\"Twitter Profile Stats:\")\n",
    "print(f\"personal_twitter_profile present: {twitter_with_value}\")\n",
    "print(f\"Valid links: {twitter_valid}\")\n",
    "print(f\"Invalid links: {twitter_invalid}\")\n",
    "print(f\"Missing/null personal_twitter_profile: {twitter_missing}\")\n",
    "print()\n",
    "print(\"LinkedIn Profile Stats:\")\n",
    "print(f\"personal_linkedin_url present: {linkedin_with_value}\")\n",
    "print(f\"Valid links: {linkedin_valid}\")\n",
    "print(f\"Invalid links: {linkedin_invalid}\")\n",
    "print(f\"Missing/null personal_linkedin_url: {linkedin_missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b809c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 874 entries with valid Twitter profiles to /Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_with_twitter.json\n",
      "Saved 1749 entries with valid LinkedIn profiles to /Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_with_linkedin.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "INPUT_PATH = \"/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_enriched_only.json\"\n",
    "OUTPUT_TWITTER = \"/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_with_twitter.json\"\n",
    "OUTPUT_LINKEDIN = \"/Users/darshil/projects/freemoney/darshil_local/american_entries_max_100k_with_linkedin.json\"\n",
    "\n",
    "with open(INPUT_PATH, \"r\") as infile:\n",
    "    enriched_only = json.load(infile)\n",
    "\n",
    "\n",
    "def is_valid_twitter_url(url: str) -> bool:\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return False\n",
    "    parsed = urlparse(url.strip())\n",
    "    if parsed.scheme not in (\"http\", \"https\"):\n",
    "        return False\n",
    "    host = (parsed.netloc or \"\").lower()\n",
    "    if not (host.endswith(\"twitter.com\") or host.endswith(\"x.com\")):\n",
    "        return False\n",
    "    username = (parsed.path or \"\").strip(\"/\")\n",
    "    if not username:\n",
    "        return False\n",
    "    if \"/\" in username:\n",
    "        return False\n",
    "    return re.fullmatch(r\"[A-Za-z0-9_]{1,15}\", username) is not None\n",
    "\n",
    "\n",
    "def is_valid_linkedin_url(url: str) -> bool:\n",
    "    if not isinstance(url, str) or not url.strip():\n",
    "        return False\n",
    "    parsed = urlparse(url.strip())\n",
    "    if parsed.scheme not in (\"http\", \"https\"):\n",
    "        return False\n",
    "    host = (parsed.netloc or \"\").lower()\n",
    "    if not host.endswith(\"linkedin.com\"):\n",
    "        return False\n",
    "    path = (parsed.path or \"\").strip(\"/\")\n",
    "    if not path:\n",
    "        return False\n",
    "    # Prefer personal profiles: linkedin.com/in/<slug>\n",
    "    segments = [seg for seg in path.split(\"/\") if seg]\n",
    "    if len(segments) < 2:\n",
    "        return False\n",
    "    if segments[0] != \"in\":\n",
    "        # allow some leniency but still require at least two segments\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "with_twitter = []\n",
    "with_linkedin = []\n",
    "\n",
    "for entry in enriched_only:\n",
    "    enrichment = entry.get(\"enrichment\") or {}\n",
    "    tw = enrichment.get(\"personal_twitter_profile\")\n",
    "    li = enrichment.get(\"personal_linkedin_url\")\n",
    "\n",
    "    if is_valid_twitter_url(tw) if tw else False:\n",
    "        with_twitter.append(entry)\n",
    "    if is_valid_linkedin_url(li) if li else False:\n",
    "        with_linkedin.append(entry)\n",
    "\n",
    "with open(OUTPUT_TWITTER, \"w\") as f_tw:\n",
    "    json.dump(with_twitter, f_tw, ensure_ascii=False)\n",
    "with open(OUTPUT_LINKEDIN, \"w\") as f_li:\n",
    "    json.dump(with_linkedin, f_li, ensure_ascii=False)\n",
    "\n",
    "print(f\"Saved {len(with_twitter)} entries with valid Twitter profiles to {OUTPUT_TWITTER}\")\n",
    "print(f\"Saved {len(with_linkedin)} entries with valid LinkedIn profiles to {OUTPUT_LINKEDIN}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589944e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
